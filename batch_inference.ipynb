{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "372fcb96-f644-4113-bd9a-9ad74fd5deeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/yjhllm/miniconda3/envs/ccks/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72dc3b7224894986b5bb133c806a0b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from modelscope import AutoTokenizer, AutoModel\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "\n",
    "def build_transform(input_size):\n",
    "    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    "    return transform\n",
    "\n",
    "\n",
    "def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):\n",
    "    best_ratio_diff = float('inf')\n",
    "    best_ratio = (1, 1)\n",
    "    area = width * height\n",
    "    for ratio in target_ratios:\n",
    "        target_aspect_ratio = ratio[0] / ratio[1]\n",
    "        ratio_diff = abs(aspect_ratio - target_aspect_ratio)\n",
    "        if ratio_diff < best_ratio_diff:\n",
    "            best_ratio_diff = ratio_diff\n",
    "            best_ratio = ratio\n",
    "        elif ratio_diff == best_ratio_diff:\n",
    "            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:\n",
    "                best_ratio = ratio\n",
    "    return best_ratio\n",
    "\n",
    "\n",
    "def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):\n",
    "    orig_width, orig_height = image.size\n",
    "    aspect_ratio = orig_width / orig_height\n",
    "\n",
    "    # calculate the existing image aspect ratio\n",
    "    target_ratios = set(\n",
    "        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if\n",
    "        i * j <= max_num and i * j >= min_num)\n",
    "    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])\n",
    "\n",
    "    # find the closest aspect ratio to the target\n",
    "    target_aspect_ratio = find_closest_aspect_ratio(\n",
    "        aspect_ratio, target_ratios, orig_width, orig_height, image_size)\n",
    "\n",
    "    # calculate the target width and height\n",
    "    target_width = image_size * target_aspect_ratio[0]\n",
    "    target_height = image_size * target_aspect_ratio[1]\n",
    "    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]\n",
    "\n",
    "    # resize the image\n",
    "    resized_img = image.resize((target_width, target_height))\n",
    "    processed_images = []\n",
    "    for i in range(blocks):\n",
    "        box = (\n",
    "            (i % (target_width // image_size)) * image_size,\n",
    "            (i // (target_width // image_size)) * image_size,\n",
    "            ((i % (target_width // image_size)) + 1) * image_size,\n",
    "            ((i // (target_width // image_size)) + 1) * image_size\n",
    "        )\n",
    "        # split the image\n",
    "        split_img = resized_img.crop(box)\n",
    "        processed_images.append(split_img)\n",
    "    assert len(processed_images) == blocks\n",
    "    if use_thumbnail and len(processed_images) != 1:\n",
    "        thumbnail_img = image.resize((image_size, image_size))\n",
    "        processed_images.append(thumbnail_img)\n",
    "    return processed_images\n",
    "\n",
    "\n",
    "def load_image(image_file, input_size=448, max_num=12):\n",
    "    image = Image.open(image_file).convert('RGB')\n",
    "    transform = build_transform(input_size=input_size)\n",
    "    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)\n",
    "    pixel_values = [transform(image) for image in images]\n",
    "    pixel_values = torch.stack(pixel_values)\n",
    "    return pixel_values\n",
    "\n",
    "\n",
    "def preprocess_image(file_path, dynamic=True, max_num=6, image_size=448):\n",
    "    try:\n",
    "        if dynamic:\n",
    "            return load_image(file_path, max_num=max_num).to(torch.bfloat16).cuda()\n",
    "        else:\n",
    "            img = Image.open(file_path).convert('RGB')\n",
    "            transform = build_transform(image_size)\n",
    "            pixel_values = transform(img)\n",
    "            return torch.stack([pixel_values]).to(torch.bfloat16).cuda()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error processing image: {e}\")\n",
    "\n",
    "\n",
    "path = \"Reyes-8B\"\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ").eval().cuda()\n",
    "\n",
    "# print(model)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=False)\n",
    "generation_config = dict(max_new_tokens=2048, do_sample=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415bc19a-2f9c-45a3-b9a7-345f5a5660c3",
   "metadata": {},
   "source": [
    "# 方式1：串行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdbb6099-2e4b-46bd-b677-72f537563742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: <image>\n",
      "Describe this image.\n",
      "Assistant: The image captures a lively scene on a basketball court, with two men in yellow and purple jerseys standing in the center of the action. One of the players is wearing a yellow shirt with the number 23 on it, while the other is wearing a yellow shirt with the number 28 on it. They are both standing in front of a crowd of fans, who are watching the game with excitement.\n",
      "\n",
      "There are several other people in the background, some of whom might be teammates, while others could be coaches or fans. The atmosphere is energetic and full of anticipation as the game unfolds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: <image>\n",
      "Describe this image.\n",
      "Assistant: The image captures a lively scene on a basketball court, with two men in yellow and purple jerseys standing in the center of the action. One of the players is wearing a yellow shirt with the number 23 on it, while the other is wearing a yellow shirt with the number 28 on it. They are both standing in front of a crowd of fans, who are watching the game with excitement.\n",
      "\n",
      "There are several other people in the background, some of whom might be teammates, while others could be coaches or fans. The atmosphere is energetic and full of anticipation as the game unfolds.\n",
      "User: <image>\n",
      "Describe this image.\n",
      "Assistant: The image captures a lively scene on a basketball court, with two men in yellow and purple jerseys standing in the center of the action. One of the players is wearing a yellow shirt with the number 23 on it, while the other is wearing a yellow shirt with the number 28 on it. They are both standing in front of a crowd of fans, who are watching the game with excitement.\n",
      "\n",
      "There are several other people in the background, some of whom might be teammates, while others could be coaches or fans. The atmosphere is energetic and full of anticipation as the game unfolds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = 't6.png'\n",
    "pixel_values = preprocess_image(file_path, dynamic=True)\n",
    "question = '<image>\\nDescribe this image.'\n",
    "response = model.chat(tokenizer, pixel_values, question, generation_config)\n",
    "print(f'User: {question}\\nAssistant: {response}')\n",
    "\n",
    "\n",
    "file_path = 't6.png'\n",
    "pixel_values = preprocess_image(file_path, dynamic=True)\n",
    "question = '<image>\\nDescribe this image.'\n",
    "response = model.chat(tokenizer, pixel_values, question, generation_config)\n",
    "print(f'User: {question}\\nAssistant: {response}')\n",
    "\n",
    "\n",
    "file_path = 't6.png'\n",
    "pixel_values = preprocess_image(file_path, dynamic=True)\n",
    "question = '<image>\\nDescribe this image.'\n",
    "response = model.chat(tokenizer, pixel_values, question, generation_config)\n",
    "print(f'User: {question}\\nAssistant: {response}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b53dc-0dc4-42e2-b070-1bd8100e0df4",
   "metadata": {},
   "source": [
    "# 方式2：batch推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a179194f-a8b5-4979-bd49-5bc0de1264c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: <image>\n",
      "Describe this image.\n",
      "Assistant: The image captures a lively scene on a basketball court, with two men in yellow and purple jerseys standing in the center of the action. One of the players is wearing a yellow shirt with the number 23 on it, while the other is in a yellow and purple jersey. They are both standing near each other, celebrating a successful play or cheering on their teammates.\n",
      "\n",
      "In the background, there are several other people, likely teammates or opponents, scattered across the court. Some of them are closer to the foreground, while others are further away in the background. The overall atmosphere of the scene is energetic and full of excitement, typical of a thrilling basketball game.\n",
      "\n",
      "User: <image>\n",
      "Describe this image.\n",
      "Assistant: The image captures a lively scene on a basketball court, with two men in yellow and purple jerseys standing in the center of the action. One of the players is wearing a yellow shirt with the number 23 on it, while the other is in a yellow and purple jersey. They are both standing near each other, celebrating a successful play or cheering on their teammates.\n",
      "\n",
      "In the background, there are several other people, likely teammates or opponents, scattered across the court. Some of them are closer to the foreground, while others are further away in the background. The overall atmosphere of the scene is energetic and full of excitement, typical of a thrilling basketball game.\n",
      "\n",
      "User: <image>\n",
      "Describe this image.\n",
      "Assistant: The image captures a lively scene on a basketball court, with two men in yellow and purple jerseys standing in the center of the action. One of the players is wearing a yellow shirt with the number 23 on it, while the other is in a yellow and purple jersey. They are both standing near each other, celebrating a successful play or cheering on their teammates.\n",
      "\n",
      "In the background, there are several other people, likely teammates or opponents, scattered across the court. Some of them are closer to the foreground, while others are further away in the background. The overall atmosphere of the scene is energetic and full of excitement, typical of a thrilling basketball game.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nvtx\n",
    "import time \n",
    "\n",
    "\n",
    "questions = [\n",
    "    \"<image>\\nDescribe this image.\",\n",
    "    \"<image>\\nDescribe this image.\",\n",
    "    \"<image>\\nDescribe this image.\",\n",
    "]\n",
    "\n",
    "images_path = [\"t6.png\",\"t6.png\",\"t6.png\"]\n",
    "\n",
    "\n",
    "def conversation(model, tokenizer, questions, images_path,generation_config,histories):\n",
    "    pixel_values_list=[]\n",
    "\n",
    "    for i in range(len(questions)):\n",
    "        if images_path[i] is not None:\n",
    "            pixel_values = preprocess_image(file_path, dynamic=True)\n",
    "            pixel_values_list.append(pixel_values)\n",
    "\n",
    "\n",
    "    return model.chat_batch(tokenizer, pixel_values_list, questions, generation_config, histories, return_histories=False)\n",
    "\n",
    "responses= conversation(model, tokenizer, questions, images_path,generation_config,histories=None)\n",
    "for question, response in zip(questions, responses):\n",
    "    print(f\"User: {question}\\nAssistant: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d25e6-0b66-46a7-8538-56681d74c428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
